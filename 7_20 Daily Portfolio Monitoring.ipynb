{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82628dbd-675d-4621-948f-75018f281954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#set up\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from utils import policy_dict, policy_data_dict, find_non_zero_riskweight_rules, find_zero_riskweight_rules\n",
    "from pandasql import sqldf\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Standard data manipulation and visualization packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', 100)      # Show 100 rows max\n",
    "pd.set_option('display.width', None)        # Auto-detect display width\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)  # Format floats to 3 decimal places\n",
    "\n",
    "# Plotting settings\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = [12, 6]  # Set default figure size\n",
    "\n",
    "\n",
    "from pysnowflake import Session\n",
    "run_query = lambda query: sqldf(query, globals())\n",
    "\n",
    "user_name = 'jobyg' #replace it with your ldap name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed931332-bd37-401e-99d5-09bffb4b31c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_name = 'jobyg' #replace it with your ldap name\n",
    "sess = Session(\n",
    "   connection_override_args={\n",
    "       'autocommit': True,\n",
    "       'authenticator': 'externalbrowser',\n",
    "       'account': 'square',\n",
    "       'database': f'PERSONAL_{user_name.upper()}',\n",
    "       'user': f'{user_name}@squareup.com'\n",
    "   }\n",
    "   \n",
    ")\n",
    "conn = sess.open()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3a30be-e6dc-4a7b-a37a-4924d0423301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ed33cd1-d0be-42c2-826c-777cdc32efab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83d0fa64-ed84-405d-9b75-bcab0c0e4917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conn.execute('use warehouse ADHOC__LARGE')\n",
    "conn.execute('use database AP_CUR_FRDRISK_G')\n",
    "conn.execute('use schema public')\n",
    "rt_start_time =  (datetime.now().today()- timedelta(days=2)).strftime(\"%Y-%m-%d\")\n",
    "first_start_date=  (datetime.now().today()- timedelta(days=60)).strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dc9a865-91d3-4912-be2b-6ac01f906098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_base_tables(user_name=user_name, rt_start_date=rt_start_time, first_start_date=first_start_date,\n",
    "conn=conn):\n",
    "    \n",
    "    print('creating attempt base')\n",
    "    attempt_driver_q = f'''    \n",
    "create or replace temp table jobys_latest_attempts as (\n",
    "select a.*, b.p2_overdue_d0_local, b.p2_due_local\n",
    "from ap_cur_r_frdrisk.curated_fraud_risk_red.unified_feature_datamart_base__{user_name}_dsl3_sv a\n",
    "left join AP_CUR_RISKBI_G.curated_risk_bi_green.dwm_order_loss_tagging b\n",
    "on a.order_token = b.order_token\n",
    "-- where (bp_is_sup = 1 and days_since_first_order_date <= 14 and a.par_region in ('GB', 'US')\n",
    "where  days_since_first_order_date <= 14 and a.par_region in ('GB', 'US','AU') and a.checkpoint = 'CHECKOUT_CONFIRM'\n",
    "and a.par_process_date >= '{first_start_date}'\n",
    "and dedup = 1\n",
    ");\n",
    "'''\n",
    "    conn.execute(attempt_driver_q)\n",
    "\n",
    "    print('creating decline base')\n",
    "\n",
    "    rt_driver_decline_q = f'''    \n",
    "create or replace temp table rt_Declines as (\n",
    "SELECT order_token, rule_id, par_Region, EVENT_INFO_EVENT_TIME,rule_category\n",
    "    FROM  AP_CUR_R_FEATSCI.curated_feature_science_red.RAW_C_E_FC_DECISION_RECORD_RULES_RT__{user_name}_DSL3_SV\n",
    "    where checkpoint in ('CHECKOUT_CONFIRM')\n",
    "    AND ((is_rejected = 'True' and is_in_treatment ilike 'True'))    \n",
    "    AND par_process_date >=  '{rt_start_date}'\n",
    "    AND par_Region in ('AU','GB', 'US')\n",
    "    and rule_id in (\n",
    "'au_fraud_online_new_overdue_v3_general'\n",
    ",'anz_abusive_fraud_online_whitepages_network_score_2024'\n",
    ",'au_order_velocity_rule_new'\n",
    ",'ANZ_FRAUD_TMX_ONLINE_NEW_USERS_V1'\n",
    ",'au_fraud_online_recurring_payment_seed_based_linking_rule_v2_migrated'\n",
    ",'anz_abusive_fraud_online_same_merch_email_streaming_2024'\n",
    ",'anz_fraud_newconsumer_overdue_v1_replacement'\n",
    ",'au_online_duplicate_account_identity_type'\n",
    ",'au_fraud_doordash_decl_history_velocity_rule_v2_migrated'\n",
    ",'anz_abusive_fraud_online_order_velocity_2024'\n",
    ",'au_fraud_online_HRM_payback_model_v3_fast'\n",
    ",'AU_fraud_online_new_user_session_device_linking_eval'\n",
    ",'anz_fraud_online_newconsumer_device_check_RE_v2_migrated'\n",
    ",'au_fraud_online_quasi_duplicate_account_written_off'\n",
    ",'au_fraud_online_card_sharing_new_consumer'\n",
    ",'au_fraud_online_new_consumer_not_first_order_v2_migrated'\n",
    ",'anz_fraud_online_hrm_travel'\n",
    ",'anz_fraud_online_cc_mismatch_email_age_v2_migrated'\n",
    ",'AU_Online_doordash_high_risk'\n",
    ",'au_fraud_udf_duplicate_account_freeze'\n",
    ",'AU_fraud_online_new_user_risky_card_creation_date'\n",
    ",'au_fraud_online_profile_change_phone_new_user'\n",
    ",'au_fraud_online_suspicious_group_acount_tier1'\n",
    ",'anz_fraud_online_velocity_acct_same_merch_email_new_v2_migrated'\n",
    ",'au_fraud_online_electless_collusion_trend'\n",
    "\n",
    "\n",
    "--GB SUP\n",
    ",'GB_fraud_sup_strategy_odv3_general'\n",
    ",'eu_fraud_online_seed_based_linking_rule_v2_migrated'\n",
    ",'uk_fraud_online_sup_wpp_phone_check_decline'\n",
    ",'eu_order_velocity_rule_new'\n",
    ",'uk_fraud_online_delphi_v3_t14_sup_non_first_order'\n",
    ",'UK_FRAUD_TMX_ONLINE_NEW_USERS_V1'\n",
    ",'uk_fraud_online_allconsumer_device_check_RE_v2_migrated'\n",
    ",'gb_fraud_online_quasi_duplicate_account_written_off'\n",
    ",'eu_fraud_online_wpp_network_score'\n",
    ",'eu_fraud_online_velocity_order_cnt_same_merch_email_new_streaming_v2_migrated'\n",
    ",'GB_fraud_online_new_user_session_device_linking'\n",
    ",'eu_fraud_online_velocity_order_amt_same_merch_email_new_streaming_v2_migrated'\n",
    ",'eu_fraud_online_duplicate_accounts_tier2_udf_decline'\n",
    ",'eu_fraud_online_duplicate_accounts_tier2_decline_v2_migrated'\n",
    ",'eu_fraud_online_fraud_decline_repeated_freeze'\n",
    ",'GB_fraud_online_new_user_risky_card_bin'\n",
    ",'gb_fraud_online_profile_change_phone_new_user'\n",
    ",'gb_fraud_online_quasi_duplicate_account_decline'\n",
    ",'gb_fraud_online_card_sharing_new_consumer'\n",
    ",'gb_fraud_online_suspicious_group_acount_tier1'\n",
    ",'gb_online_payment_reschedule'\n",
    ",'eu_fraud_online_velocity_acct_same_merch_email_new_streaming_v2_migrated'\n",
    ",'eu_fraud_online_duplicate_account_collection_seed'\n",
    ",'eu_fraud_udf_duplicate_account'\n",
    ",'eu_fraud_online_velocity_acct_same_merch_email_new_v2_migrated'\n",
    ",'GB_fraud_online_new_user_risky_card_issuing_bank'\n",
    ",'gb_fraud_online_velocity_new_existing_6h_K_v2_migrated'\n",
    ",'GB_fraud_online_new_user_risky_email_domain'\n",
    ",'GB_online_high_order_velocity_rule_v2_migrated'\n",
    ",'gb_fraud_online_same_merch_velocity'\n",
    ",'EU_abusive_online_emailage_rule'\n",
    "\n",
    "--US SUP\n",
    ",'US_fraud_sup_strategy_odv3_general'\n",
    ",'us_fraud_online_sup_transaction_model_wpp_info_mismatch_v1'\n",
    ",'us_fraud_online_seed_based_linking_rule_v2_migrated'\n",
    ",'NA_FRAUD_TMX_ONLINE_NEW_USERS_V1'\n",
    ",'us_fraud_online_whitepages_general_decline'\n",
    ",'us_fraud_udf_income_zipcode'\n",
    ",'cash_credit_abuse_model_rule_v3'\n",
    ",'us_sup_order_velocity_rule_new'\n",
    ",'us_fraud_udf_duplicate_account'\n",
    ",'US_fraud_online_new_user_session_device_linking'\n",
    ",'us_fraud_online_quasi_duplicate_account_written_off'\n",
    ",'US_fraud_online_new_user_risky_card_issuing_bank'\n",
    ",'us_fraud_online_duplicate_accounts_tier2_udf_decline'\n",
    ",'us_fraud_online_duplicate_accounts_tier2_decline_v2_migrated'\n",
    ",'cash_credit_abuse_model_rule_realtime_v2'\n",
    ",'us_fraud_online_fraud_decline_repeated_freeze'\n",
    ",'us_fraud_online_profile_change_fraud_decline'\n",
    ",'us_fraud_online_card_sharing_new_consumer'\n",
    ",'us_fraud_online_velocity_same_merch_email_decline'\n",
    ",'us_fraud_online_profile_change_phone_new_user'\n",
    ",'us_fraud_udf_duplicate_account_freeze'\n",
    ",'us_fraud_online_duplicate_account_collection_seed'\n",
    ",'US_fraud_online_new_user_risky_card_bin'\n",
    ",'us_fraud_online_quasi_duplicate_account_decline'\n",
    ",'US_online_newuser_order_velocity_decline'\n",
    ",'us_fraud_online_suspicious_group_acount_v2_migrated'\n",
    ",'US_fraud_online_new_user_risky_email_domain'\n",
    ",'us_fraud_online_suspicious_group_acount_tier3_v2_migrated'\n",
    ",'us_fraud_online_velocity_acct_same_merch_email_new_streaming_v2_migrated'\n",
    ",'us_fraud_online_payment_reschedule'\n",
    ",'us_fraud_online_new_risky_card_issuing_bank'\n",
    ",'us_fraud_online_suspicious_group_acount_tier2_v2_migrated'\n",
    ",'us_fraud_online_duplicate_gmail_accts_new'\n",
    ",'us_fraud_sup_strategy_whitepages_general_v2'\n",
    ",'us_fraud_online_velocity_acct_same_merch_email_new_V2'\n",
    "\n",
    "-- US ONLINE\n",
    "\n",
    ",'NA_FRAUD_TMX_ONLINE_NEW_USERS_V1'\n",
    ",'US_abusive_online_emailage_rule'\n",
    "));\n",
    "'''\n",
    "    conn.execute(rt_driver_decline_q)\n",
    "\n",
    "    old_driver_decline_q = f'''create or replace temp table old_declines as (\n",
    "SELECT order_token, rule_id, par_Region, EVENT_INFO_EVENT_TIME, rule_category\n",
    "    FROM  AP_CUR_R_FEATSCI.curated_feature_science_red.tBL_RAW_C_E_FC_DECISION_RECORD_RULES__{user_name}_DSL3_SV\n",
    "    where checkpoint in ('CHECKOUT_CONFIRM')\n",
    "    AND ((is_rejected = 'True' and is_in_treatment ilike 'True'))    \n",
    "    AND par_Region in ('AU','GB', 'US')\n",
    "    and rule_id in (\n",
    "'au_fraud_online_new_overdue_v3_general'\n",
    ",'anz_abusive_fraud_online_whitepages_network_score_2024'\n",
    ",'au_order_velocity_rule_new'\n",
    ",'ANZ_FRAUD_TMX_ONLINE_NEW_USERS_V1'\n",
    ",'au_fraud_online_recurring_payment_seed_based_linking_rule_v2_migrated'\n",
    ",'anz_abusive_fraud_online_same_merch_email_streaming_2024'\n",
    ",'anz_fraud_newconsumer_overdue_v1_replacement'\n",
    ",'au_online_duplicate_account_identity_type'\n",
    ",'au_fraud_doordash_decl_history_velocity_rule_v2_migrated'\n",
    ",'anz_abusive_fraud_online_order_velocity_2024'\n",
    ",'au_fraud_online_HRM_payback_model_v3_fast'\n",
    ",'AU_fraud_online_new_user_session_device_linking_eval'\n",
    ",'anz_fraud_online_newconsumer_device_check_RE_v2_migrated'\n",
    ",'au_fraud_online_quasi_duplicate_account_written_off'\n",
    ",'au_fraud_online_card_sharing_new_consumer'\n",
    ",'au_fraud_online_new_consumer_not_first_order_v2_migrated'\n",
    ",'anz_fraud_online_hrm_travel'\n",
    ",'anz_fraud_online_cc_mismatch_email_age_v2_migrated'\n",
    ",'AU_Online_doordash_high_risk'\n",
    ",'au_fraud_udf_duplicate_account_freeze'\n",
    ",'AU_fraud_online_new_user_risky_card_creation_date'\n",
    ",'au_fraud_online_profile_change_phone_new_user'\n",
    ",'au_fraud_online_suspicious_group_acount_tier1'\n",
    ",'anz_fraud_online_velocity_acct_same_merch_email_new_v2_migrated'\n",
    ",'au_fraud_online_electless_collusion_trend'\n",
    "\n",
    "--GB SUP\n",
    ",'GB_fraud_sup_strategy_odv3_general'\n",
    ",'eu_fraud_online_seed_based_linking_rule_v2_migrated'\n",
    ",'uk_fraud_online_sup_wpp_phone_check_decline'\n",
    ",'eu_order_velocity_rule_new'\n",
    ",'uk_fraud_online_delphi_v3_t14_sup_non_first_order'\n",
    ",'UK_FRAUD_TMX_ONLINE_NEW_USERS_V1'\n",
    ",'uk_fraud_online_allconsumer_device_check_RE_v2_migrated'\n",
    ",'gb_fraud_online_quasi_duplicate_account_written_off'\n",
    ",'eu_fraud_online_wpp_network_score'\n",
    ",'eu_fraud_online_velocity_order_cnt_same_merch_email_new_streaming_v2_migrated'\n",
    ",'GB_fraud_online_new_user_session_device_linking'\n",
    ",'eu_fraud_online_velocity_order_amt_same_merch_email_new_streaming_v2_migrated'\n",
    ",'eu_fraud_online_duplicate_accounts_tier2_udf_decline'\n",
    ",'eu_fraud_online_duplicate_accounts_tier2_decline_v2_migrated'\n",
    ",'eu_fraud_online_fraud_decline_repeated_freeze'\n",
    ",'GB_fraud_online_new_user_risky_card_bin'\n",
    ",'gb_fraud_online_profile_change_phone_new_user'\n",
    ",'gb_fraud_online_quasi_duplicate_account_decline'\n",
    ",'gb_fraud_online_card_sharing_new_consumer'\n",
    ",'gb_fraud_online_suspicious_group_acount_tier1'\n",
    ",'gb_online_payment_reschedule'\n",
    ",'eu_fraud_online_velocity_acct_same_merch_email_new_streaming_v2_migrated'\n",
    ",'eu_fraud_online_duplicate_account_collection_seed'\n",
    ",'eu_fraud_udf_duplicate_account'\n",
    ",'eu_fraud_online_velocity_acct_same_merch_email_new_v2_migrated'\n",
    ",'GB_fraud_online_new_user_risky_card_issuing_bank'\n",
    ",'gb_fraud_online_velocity_new_existing_6h_K_v2_migrated'\n",
    ",'GB_fraud_online_new_user_risky_email_domain'\n",
    ",'GB_online_high_order_velocity_rule_v2_migrated'\n",
    ",'gb_fraud_online_same_merch_velocity'\n",
    ",'EU_abusive_online_emailage_rule'\n",
    "\n",
    "--US SUP\n",
    ",'US_fraud_sup_strategy_odv3_general'\n",
    ",'us_fraud_online_sup_transaction_model_wpp_info_mismatch_v1'\n",
    ",'us_fraud_online_seed_based_linking_rule_v2_migrated'\n",
    ",'NA_FRAUD_TMX_ONLINE_NEW_USERS_V1'\n",
    ",'us_fraud_online_whitepages_general_decline'\n",
    ",'us_fraud_udf_income_zipcode'\n",
    ",'cash_credit_abuse_model_rule_v3'\n",
    ",'us_sup_order_velocity_rule_new'\n",
    ",'us_fraud_udf_duplicate_account'\n",
    ",'US_fraud_online_new_user_session_device_linking'\n",
    ",'us_fraud_online_quasi_duplicate_account_written_off'\n",
    ",'US_fraud_online_new_user_risky_card_issuing_bank'\n",
    ",'us_fraud_online_duplicate_accounts_tier2_udf_decline'\n",
    ",'us_fraud_online_duplicate_accounts_tier2_decline_v2_migrated'\n",
    ",'cash_credit_abuse_model_rule_realtime_v2'\n",
    ",'us_fraud_online_fraud_decline_repeated_freeze'\n",
    ",'us_fraud_online_profile_change_fraud_decline'\n",
    ",'us_fraud_online_card_sharing_new_consumer'\n",
    ",'us_fraud_online_velocity_same_merch_email_decline'\n",
    ",'us_fraud_online_profile_change_phone_new_user'\n",
    ",'us_fraud_udf_duplicate_account_freeze'\n",
    ",'us_fraud_online_duplicate_account_collection_seed'\n",
    ",'US_fraud_online_new_user_risky_card_bin'\n",
    ",'us_fraud_online_quasi_duplicate_account_decline'\n",
    ",'US_online_newuser_order_velocity_decline'\n",
    ",'us_fraud_online_suspicious_group_acount_v2_migrated'\n",
    ",'US_fraud_online_new_user_risky_email_domain'\n",
    ",'us_fraud_online_suspicious_group_acount_tier3_v2_migrated'\n",
    ",'us_fraud_online_velocity_acct_same_merch_email_new_streaming_v2_migrated'\n",
    ",'us_fraud_online_payment_reschedule'\n",
    ",'us_fraud_online_new_risky_card_issuing_bank'\n",
    ",'us_fraud_online_suspicious_group_acount_tier2_v2_migrated'\n",
    ",'us_fraud_online_duplicate_gmail_accts_new'\n",
    ",'us_fraud_sup_strategy_whitepages_general_v2'\n",
    ",'us_fraud_online_velocity_acct_same_merch_email_new_V2'\n",
    "\n",
    "--US ONLINE\n",
    ",'NA_FRAUD_TMX_ONLINE_NEW_USERS_V1'\n",
    ",'US_abusive_online_emailage_rule'\n",
    ")\n",
    "\n",
    "    AND par_process_date >=  '{first_start_date}'\n",
    "    and par_process_date <= '{rt_start_date}');'''\n",
    "\n",
    "    conn.execute(old_driver_decline_q)\n",
    "\n",
    "    conn.execute('''create or replace temp table full_declines as (\n",
    "select * from rt_declines union select * from old_Declines\n",
    ");''')\n",
    "    \n",
    "    print('working on unique declines')\n",
    "\n",
    "    conn.execute(f'''create or replace temp table unique_declines_rt as (\n",
    "SELECT order_token, count(distinct(rule_id)) as rule_ct, \n",
    "    FROM  AP_CUR_R_FEATSCI.curated_feature_science_red.RAW_C_E_FC_DECISION_RECORD_RULES_RT__{user_name}_DSL3_SV\n",
    "    where checkpoint in ('CHECKOUT_CONFIRM')\n",
    "    AND ((is_rejected = 'True' and is_in_treatment ilike 'True'))    \n",
    "    AND par_Region in ('GB','US','AU')\n",
    "    AND par_process_date >=  '{first_start_date}'\n",
    "    and par_process_date <= '{rt_start_date}'\n",
    "    group by 1\n",
    "    having  count(distinct(rule_id)) = 1\n",
    ");''')\n",
    "    \n",
    "    conn.execute(f'''\n",
    "                 create or replace temp table unique_declines_old as (\n",
    "SELECT order_token, count(distinct(rule_id)) as rule_ct, \n",
    "    FROM  AP_CUR_R_FEATSCI.curated_feature_science_red.TBL_RAW_C_E_FC_DECISION_RECORD_RULES__{user_name}_DSL3_SV\n",
    "    where checkpoint in ('CHECKOUT_CONFIRM')\n",
    "    AND ((is_rejected = 'True' and is_in_treatment ilike 'True'))    \n",
    "    AND par_process_date >=  '{first_start_date}'\n",
    "    and par_process_date <= '{rt_start_date}'\n",
    "    AND par_Region in ('GB','US','AU')\n",
    "    group by 1\n",
    "    having  count(distinct(rule_id)) = 1\n",
    "); ''')\n",
    "    \n",
    "    conn.execute('''create or replace temp table unique_declines as (\n",
    "select * from unique_declines_rt union select * from unique_declines_old\n",
    ");''')\n",
    "    \n",
    "    print('working on trust')\n",
    "    conn.execute(f'''create or replace temp table trust_rt as (\n",
    "SELECT order_token, count(distinct(rule_id)) as rule_ct, \n",
    "    FROM  AP_CUR_R_FEATSCI.curated_feature_science_red.RAW_C_E_FC_DECISION_RECORD_RULES_RT__{user_name}_DSL3_SV\n",
    "    where checkpoint in ('CHECKOUT_CONFIRM')\n",
    "    AND actions ilike '%trust%'\n",
    "    AND par_Region in ('GB','US','AU')\n",
    "    AND par_process_date >=  '{first_start_date}'\n",
    "    and par_process_date <= '{rt_start_date}'\n",
    "    group by 1\n",
    ");''')\n",
    "    conn.execute(f'''create or replace temp table trust_old as (\n",
    "SELECT order_token, count(distinct(rule_id)) as rule_ct, \n",
    "    FROM  AP_CUR_R_FEATSCI.curated_feature_science_red.TBL_RAW_C_E_FC_DECISION_RECORD_RULES__{user_name}_DSL3_SV\n",
    "    where checkpoint in ('CHECKOUT_CONFIRM')\n",
    "    AND actions ilike '%trust%'\n",
    "    AND par_process_date >=  '{first_start_date}'\n",
    "    and par_process_date <= '{rt_start_date}'\n",
    "    AND par_region in ('GB','US','AU')\n",
    "    group by 1\n",
    ");''')\n",
    "\n",
    "    conn.execute('''create or replace temp table trust as (\n",
    "select * from trust_rt union select * from trust_old\n",
    ");''')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b2b390b-6920-4e70-8087-6030cbfeeddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_base_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f847caa6-8933-4d8c-8781-1ebadd9109e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = conn.download('''\n",
    "                                  select\n",
    "a.par_Region,\n",
    "par_process_date\n",
    ",bp_is_sup\n",
    ",count(distinct(a.order_token)) as attempt_ct\n",
    ",count(distinct(a.order_token_loss)) as approved_order_Ct\n",
    ",sum(in_flight_order_amount) as attempt_Amt\n",
    ",sum(order_amount_local) as approved_amt\n",
    ",count(distinct b.order_token) as decline_Ct\n",
    ",div0(count(distinct b.order_token),count(distinct(a.order_token))) as decline_rt\n",
    ",div0(count(distinct order_Token_loss),count(distinct(a.order_token))) as decline_including_Trust\n",
    ",div0(sum(p2_overdue_d0_local),sum(p2_due_local)) as approved_p2d0\n",
    ",div0(sum(case when is_in_attempt_control_Group = 1 then p2_overdue_d0_local end),sum(case when is_in_attempt_control_Group = 1 then p2_due_local end)) as ctrl_Group_p2d0\n",
    ",div0(sum(p2_overdue_d0_local),sum( p2_due_local)) as portfolio_p2_do\n",
    "\n",
    ",sum(case when b.order_Token is not null then in_flight_order_amount end) as decline_amt\n",
    "from jobys_latest_attempts a\n",
    "left join full_declines b\n",
    "on a.order_token = b.order_token\n",
    "where a.par_process_date >=  DATEADD('day', -60, CURRENT_DATE())\n",
    "-- and a.par_region = 'US'\n",
    "-- and bp_is_sup = 1\n",
    "group by 1,2,3\n",
    "order by 1,2,3 desc;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b364a6fe-9fe7-410d-ab55-a49ed0b2c581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "portfolio_metrics.columns\n",
    "# import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f188da3-17d9-4379-877d-699c8e2425e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Filter by bp_is_sup values ---\n",
    "df_sup_1 = df[df['bp_is_sup'] == 1]\n",
    "df_sup_0 = df[df['bp_is_sup'] == 0]\n",
    "\n",
    "# --- Step 2: Group and aggregate the data by date and region ---\n",
    "df_sup_1_agg = df_sup_1.groupby(['par_process_date', 'par_region'])['decline_rt'].mean().reset_index()\n",
    "df_sup_0_agg = df_sup_0.groupby(['par_process_date', 'par_region'])['decline_rt'].mean().reset_index()\n",
    "\n",
    "# --- Step 3: Plot for bp_is_sup = 1 ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=df_sup_1_agg,\n",
    "    x='par_process_date',\n",
    "    y='decline_rt',\n",
    "    hue='par_region',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('Decline Rate Over Time by Region (bp_is_sup = 1)')\n",
    "plt.xlabel('Processing Date')\n",
    "plt.ylabel('Decline Rate')\n",
    "plt.legend(title='Region')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9977092-e95a-406a-b5d7-cc88e62f3617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def summarize_and_compare_metrics_v2(df, country, bp_is_sup, p2d0_lag_days=15):\n",
    "    df = df[(df['bp_is_sup'] == bp_is_sup) & (df['par_region'] == f'{country}')]\n",
    "    df['par_process_date'] = pd.to_datetime(df['par_process_date'])\n",
    "    latest_date = df['par_process_date'].max()\n",
    "\n",
    "    def get_week_bounds(reference_date):\n",
    "        end = reference_date - pd.Timedelta(days=reference_date.weekday() - 6)\n",
    "        start = end - pd.Timedelta(days=6)\n",
    "        prev_end = start - pd.Timedelta(days=1)\n",
    "        prev_start = prev_end - pd.Timedelta(days=6)\n",
    "        return (start, end, prev_start, prev_end)\n",
    "\n",
    "    def pct_change(current, previous):\n",
    "        if pd.isna(current) or pd.isna(previous) or previous == 0:\n",
    "            return None\n",
    "        return (current - previous) / previous * 100\n",
    "\n",
    "    def format_pct(value):\n",
    "        return f\"{value:.1f}%\" if value is not None else \"N/A\"\n",
    "\n",
    "    def format_val(value, is_pct=False):\n",
    "        if value is None:\n",
    "            return \"N/A\"\n",
    "        return f\"{value:.2%}\" if is_pct else f\"${value:,.0f}\"\n",
    "\n",
    "    def weighted_avg(df_subset):\n",
    "        attempts = df_subset['attempt_ct'].sum()\n",
    "        return (df_subset['decline_rt'] * df_subset['attempt_ct']).sum() / attempts if attempts else None\n",
    "\n",
    "    ### 1. Decline Rate\n",
    "    decline_ref = latest_date\n",
    "    cur_start, cur_end, prev_start, prev_end = get_week_bounds(decline_ref)\n",
    "\n",
    "    df_today = df[df['par_process_date'] == decline_ref]\n",
    "    df_yesterday = df[df['par_process_date'] == decline_ref - pd.Timedelta(days=1)]\n",
    "    df_wow = df[(df['par_process_date'] >= cur_start) & (df['par_process_date'] <= cur_end)]\n",
    "    df_prev_wow = df[(df['par_process_date'] >= prev_start) & (df['par_process_date'] <= prev_end)]\n",
    "\n",
    "    decline_today = weighted_avg(df_today)\n",
    "    decline_yesterday = weighted_avg(df_yesterday)\n",
    "    decline_wow = weighted_avg(df_wow)\n",
    "    decline_prev_wow = weighted_avg(df_prev_wow)\n",
    "\n",
    "    ### 2. Approved Amount\n",
    "    approved_ref = latest_date - pd.Timedelta(days=2)\n",
    "    cur_start, cur_end, prev_start, prev_end = get_week_bounds(approved_ref)\n",
    "\n",
    "    approved_today = df[df['par_process_date'] == approved_ref]['approved_amt'].sum()\n",
    "    approved_yesterday = df[df['par_process_date'] == approved_ref - pd.Timedelta(days=1)]['approved_amt'].sum()\n",
    "    # print(cur_start,cur_end)\n",
    "    approved_wow = df[(df['par_process_date'] >= cur_start) & (df['par_process_date'] <= cur_end)]['approved_amt'].sum()\n",
    "    approved_prev_wow = df[(df['par_process_date'] >= prev_start) & (df['par_process_date'] <= prev_end)]['approved_amt'].sum()\n",
    "\n",
    "    ### 3. P2D0 Rate\n",
    "    p2d0_ref = latest_date - pd.Timedelta(days=p2d0_lag_days)\n",
    "    cur_start, cur_end, prev_start, prev_end = get_week_bounds(p2d0_ref)\n",
    "\n",
    "    p2d0_today = df[df['par_process_date'] == p2d0_ref]['portfolio_p2_do'].mean()\n",
    "    p2d0_yesterday = df[df['par_process_date'] == p2d0_ref - pd.Timedelta(days=1)]['portfolio_p2_do'].mean()\n",
    "    p2d0_wow = df[(df['par_process_date'] >= cur_start) & (df['par_process_date'] <= cur_end)]['portfolio_p2_do'].mean()\n",
    "    p2d0_prev_wow = df[(df['par_process_date'] >= prev_start) & (df['par_process_date'] <= prev_end)]['portfolio_p2_do'].mean()\n",
    "\n",
    "    ### Final summary\n",
    "    lines = []\n",
    "\n",
    "    # Decline rate summary\n",
    "    dod_decline = pct_change(decline_today, decline_yesterday)\n",
    "    wow_decline = pct_change(decline_wow, decline_prev_wow)\n",
    "    if bp_is_sup:\n",
    "        lines.append(f'performance for {country} SUP is:')\n",
    "    else:\n",
    "        lines.append(f'performance for {country} Online is:')\n",
    "\n",
    "\n",
    "    lines.append(f\"ðŸ“‰ *Decline Rate* (as of {decline_ref.date()}): {format_val(decline_today, is_pct=True)} \"\n",
    "                 f\"(DoD: {format_pct(dod_decline)}, WoW: {format_pct(wow_decline)})\")\n",
    "\n",
    "    # Approved amount summary\n",
    "    dod_approved = pct_change(approved_today, approved_yesterday)\n",
    "    wow_approved = pct_change(approved_wow, approved_prev_wow)\n",
    "    lines.append(f\"ðŸ’° *Approved Amount* (as of {approved_ref.date()}): {format_val(approved_today)} \"\n",
    "                 f\"(DoD: {format_pct(dod_approved)}, WoW: {format_pct(wow_approved)})\")\n",
    "\n",
    "    # P2D0 rate summary\n",
    "    dod_p2d0 = pct_change(p2d0_today, p2d0_yesterday)\n",
    "    wow_p2d0 = pct_change(p2d0_wow, p2d0_prev_wow)\n",
    "    lines.append(f\"â±ï¸ *P2D0 Rate* (as of {p2d0_ref.date()}): {format_val(p2d0_today, is_pct=True)} \"\n",
    "                 f\"(DoD: {format_pct(dod_p2d0)}, WoW: {format_pct(wow_p2d0)})\")\n",
    "\n",
    "    output = '\\n'.join(lines)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "593169ae-6e55-4f01-a66e-1a529d9c1cd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summarize_and_compare_metrics_v2(df, 'US', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e21cf7ff-4335-4e09-b2e0-a9acce898f85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summarize_and_compare_metrics_v2(df, 'GB', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be0987ef-5d1b-4518-a296-e86eb11c313b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summarize_and_compare_metrics_v2(df, 'US', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "817b7335-9fb4-4a24-ac45-13b166f84b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summarize_and_compare_metrics_v2(df, 'AU', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6f35cae-523d-43ba-a4b6-854ef46e7dd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "week_to_date_df = conn.download('''\n",
    "select\n",
    "a.par_Region,\n",
    "to_Varchar(checkout_time,'YYYY-MM-DD HH') as checkout_time\n",
    ",bp_is_sup\n",
    ",count(distinct(a.order_token)) as attempt_ct\n",
    ",sum(order_amount_local) as approved_amt\n",
    ",count(distinct b.order_token) as decline_ct\n",
    ",sum(p2_overdue_d0_local) as p2_overdue\n",
    ",sum(p2_due_local) as p2_due_local\n",
    "from jobys_latest_attempts a\n",
    "left join full_declines b\n",
    "on a.order_token = b.order_token\n",
    "where a.par_process_date >=  DATEADD('day', -30, CURRENT_DATE())\n",
    "-- and a.par_region = 'US'\n",
    "-- and bp_is_sup = 1\n",
    "group by 1,2,3\n",
    "order by 1,2,3 desc;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f31c51d-b6c6-4ed3-84d0-b9d823d1c078",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def compare_wtd_metrics_from_hourly_df(df, now=None, region_filter=None, bp_is_sup = None):\n",
    "    # Parse checkout_time\n",
    "    df = df.copy()\n",
    "    df['checkout_time'] = pd.to_datetime(df['checkout_time'], format='%Y-%m-%d %H')\n",
    "    df = df[df['bp_is_sup'] == bp_is_sup]\n",
    "    if region_filter:\n",
    "        df = df[df['par_region'] == f'{region_filter}']\n",
    "\n",
    "    # Define \"now\"\n",
    "    now = pd.Timestamp.now() if now is None else pd.to_datetime(now)\n",
    "    current_weekday = now.weekday()\n",
    "    this_sunday = now - pd.Timedelta(days=current_weekday + 1)\n",
    "    week_start = pd.Timestamp.combine(this_sunday.date(), pd.Timestamp.min.time())\n",
    "    hour_cutoff = now.floor('H')\n",
    "\n",
    "    # Define previous week bounds\n",
    "    prev_week_start = week_start - pd.Timedelta(days=7)\n",
    "    prev_hour_cutoff = hour_cutoff - pd.Timedelta(days=7)\n",
    "\n",
    "    # Filter current and previous week data\n",
    "    current_df = df[(df['checkout_time'] >= week_start) & (df['checkout_time'] <= hour_cutoff)]\n",
    "    prev_df = df[(df['checkout_time'] >= prev_week_start) & (df['checkout_time'] <= prev_hour_cutoff)]\n",
    "\n",
    "    # Group over entire week-to-date period\n",
    "    def summarize(df_):\n",
    "        attempts = df_['attempt_ct'].sum()\n",
    "        declines = df_['decline_ct'].sum()\n",
    "        approved = df_['approved_amt'].sum()\n",
    "        p2_due = df_['p2_due_local'].sum()\n",
    "        p2_overdue = df_['p2_overdue'].sum()\n",
    "\n",
    "        decline_rt = declines / attempts if attempts else None\n",
    "        p2d0_rt = p2_overdue / p2_due if p2_due else None\n",
    "\n",
    "        return {\n",
    "            'decline_rate': decline_rt,\n",
    "            'approved_amt': approved,\n",
    "            'p2d0_rate': p2d0_rt\n",
    "        }\n",
    "\n",
    "    now_summary = summarize(current_df)\n",
    "    prev_summary = summarize(prev_df)\n",
    "\n",
    "    # Change calculations\n",
    "    def pct_change(curr, prev):\n",
    "        if curr is None or prev is None or prev == 0:\n",
    "            return None\n",
    "        return (curr - prev) / prev * 100\n",
    "\n",
    "    # Format helpers\n",
    "    def format_pct(x): return f\"{x:.1f}%\" if x is not None else \"N/A\"\n",
    "    def format_val(x, pct=False): return f\"{x:.2%}\" if pct and x is not None else f\"${x:,.0f}\" if x is not None else \"N/A\"\n",
    "\n",
    "    # Build output\n",
    "    lines = []\n",
    "    if bp_is_sup:\n",
    "        lines.append(f'performance for {region_filter} SUP is:')\n",
    "    else:\n",
    "        lines.append(f'performance for {region_filter} Online is:')\n",
    "\n",
    "    lines.append(f\"ðŸ“Š *Week-to-Date Comparison* (from {week_start.date()} to {hour_cutoff.strftime('%Y-%m-%d %H:%M')})\")\n",
    "\n",
    "    delta_decline = pct_change(now_summary['decline_rate'], prev_summary['decline_rate'])\n",
    "    lines.append(f\"ðŸ“‰ *Decline Rate*: {format_val(now_summary['decline_rate'], pct=True)} \"\n",
    "                 f\"(vs last week: {format_pct(delta_decline)})\")\n",
    "\n",
    "    delta_approved = pct_change(now_summary['approved_amt'], prev_summary['approved_amt'])\n",
    "    lines.append(f\"ðŸ’° *Approved Amount*: {format_val(now_summary['approved_amt'])} \"\n",
    "                 f\"(vs last week: {format_pct(delta_approved)})\")\n",
    "\n",
    "    delta_p2d0 = pct_change(now_summary['p2d0_rate'], prev_summary['p2d0_rate'])\n",
    "    lines.append(f\"â±ï¸ *P2D0 Rate*: {format_val(now_summary['p2d0_rate'], pct=True)} \"\n",
    "                 f\"(vs last week: {format_pct(delta_p2d0)})\")\n",
    "\n",
    "    output = '\\n'.join(lines)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434399d4-bb7c-4586-a45d-5b54055aecc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def compare_wtd_metrics_from_hourly_df(df, now=None, region_filter=None, bp_is_sup = None):\n",
    "    # Parse checkout_time\n",
    "    df = df.copy()\n",
    "    df['checkout_time'] = pd.to_datetime(df['checkout_time'], format='%Y-%m-%d %H')\n",
    "    df = df[df['bp_is_sup'] == bp_is_sup]\n",
    "    if region_filter:\n",
    "        df = df[df['par_region'] == f'{region_filter}']\n",
    "\n",
    "    now = pd.Timestamp.now() if now is None else pd.to_datetime(now)\n",
    "\n",
    "    def get_wtd_window(now_shifted):\n",
    "        weekday = now_shifted.weekday()\n",
    "        latest_sunday = now_shifted - pd.Timedelta(days=weekday + 1)\n",
    "        start = pd.Timestamp.combine(latest_sunday.date(), pd.Timestamp.min.time())\n",
    "        end = now_shifted.floor('H')\n",
    "        prev_start = start - pd.Timedelta(days=7)\n",
    "        prev_end = end - pd.Timedelta(days=7)\n",
    "        return start, end, prev_start, prev_end\n",
    "\n",
    "    def pct_change(curr, prev):\n",
    "        if curr is None or prev is None or prev == 0:\n",
    "            return None\n",
    "        return (curr - prev) / prev * 100\n",
    "\n",
    "    def format_pct(x): return f\"{x:.1f}%\" if x is not None else \"N/A\"\n",
    "    def format_val(x, pct=False): return f\"{x:.2%}\" if pct and x is not None else f\"${x:,.0f}\" if x is not None else \"N/A\"\n",
    "\n",
    "    def summarize(sub_df):\n",
    "        attempts = sub_df['attempt_ct'].sum()\n",
    "        declines = sub_df['decline_ct'].sum()\n",
    "        approved = sub_df['approved_amt'].sum()\n",
    "        p2_overdue = sub_df['p2_overdue'].sum()\n",
    "        p2_due = sub_df['p2_due_local'].sum()\n",
    "\n",
    "        decline_rt = declines / attempts if attempts else None\n",
    "        p2d0_rt = p2_overdue / p2_due if p2_due else None\n",
    "\n",
    "        return {\n",
    "            'attempts': attempts,\n",
    "            'decline_rate': decline_rt,\n",
    "            'approved_amt': approved,\n",
    "            'p2d0_rate': p2d0_rt\n",
    "        }\n",
    "\n",
    "    lines = []\n",
    "    if bp_is_sup:\n",
    "        lines.append(f'performance for {region_filter} SUP is:')\n",
    "    else:\n",
    "        lines.append(f'performance for {region_filter} Online is:')\n",
    "    ### 1. Decline Rate â€” real-time\n",
    "    d_start, d_end, d_prev_start, d_prev_end = get_wtd_window(now)\n",
    "    cur_d = df[(df['checkout_time'] >= d_start) & (df['checkout_time'] <= d_end)]\n",
    "    prev_d = df[(df['checkout_time'] >= d_prev_start) & (df['checkout_time'] <= d_prev_end)]\n",
    "\n",
    "    d_now = summarize(cur_d)\n",
    "    d_prev = summarize(prev_d)\n",
    "    d_delta = pct_change(d_now['decline_rate'], d_prev['decline_rate'])\n",
    "    lines.append(f\"ðŸ“‰ *Decline Rate* (WTD up to {d_end:%Y-%m-%d %H:%M}): \"\n",
    "                 f\"{format_val(d_now['decline_rate'], pct=True)} (vs last week: {format_pct(d_delta)})\")\n",
    "\n",
    "    ### 2. Approved Amount â€” 1-day lag\n",
    "    a_now_time = now - timedelta(days=1)\n",
    "    a_start, a_end, a_prev_start, a_prev_end = get_wtd_window(a_now_time)\n",
    "    cur_a = df[(df['checkout_time'] >= a_start) & (df['checkout_time'] <= a_end)]\n",
    "    prev_a = df[(df['checkout_time'] >= a_prev_start) & (df['checkout_time'] <= a_prev_end)]\n",
    "\n",
    "    a_now = summarize(cur_a)\n",
    "    a_prev = summarize(prev_a)\n",
    "    a_delta = pct_change(a_now['approved_amt'], a_prev['approved_amt'])\n",
    "    lines.append(f\"ðŸ’° *Approved Amount* (WTD ending {a_end:%Y-%m-%d}): \"\n",
    "                 f\"{format_val(a_now['approved_amt'])} (vs last week: {format_pct(a_delta)})\")\n",
    "\n",
    "    ### 3. P2D0 Rate â€” 14-day lag\n",
    "    p_now_time = now - timedelta(days=14)\n",
    "    p_start, p_end, p_prev_start, p_prev_end = get_wtd_window(p_now_time)\n",
    "    cur_p = df[(df['checkout_time'] >= p_start) & (df['checkout_time'] <= p_end)]\n",
    "    prev_p = df[(df['checkout_time'] >= p_prev_start) & (df['checkout_time'] <= p_prev_end)]\n",
    "\n",
    "    p_now = summarize(cur_p)\n",
    "    p_prev = summarize(prev_p)\n",
    "    p_delta = pct_change(p_now['p2d0_rate'], p_prev['p2d0_rate'])\n",
    "    lines.append(f\"â±ï¸ *P2D0 Rate* (WTD ending {p_end:%Y-%m-%d}): \"\n",
    "                 f\"{format_val(p_now['p2d0_rate'], pct=True)} (vs last week: {format_pct(p_delta)})\")\n",
    "\n",
    "    header = f\"ðŸ“Š *Adjusted Week-to-Date Comparison* (as of {now:%A %Y-%m-%d %H:%M})\"\n",
    "    output = '\\n'.join(lines)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "832cb608-8508-44a4-a624-e747d5133859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "compare_wtd_metrics_from_hourly_df(week_to_date_df, region_filter = 'US', bp_is_sup = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "061f368d-6752-42b6-93c3-e30a8028d8d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbd94478-4159-4d1c-81cb-acd44c8ee5dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rule_daily_dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f767c213-a600-47fa-a0bc-4977556628f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "focus_region='US'\n",
    "bp_is_sup=1\n",
    "conn.execute(f'''create or replace temp table decline_rt_denom as (\n",
    " select par_process_date, par_region, bp_is_sup, count(distinct(order_Token)) as token_ct from jobys_latest_attempts \n",
    "     group by 1,2,3\n",
    "    );''')\n",
    "\n",
    "rule_daily_dive = conn.download('''select\n",
    "a.par_Region,\n",
    "a.par_process_date\n",
    ",a.bp_is_sup\n",
    ",rule_id\n",
    ",count(distinct(a.order_token)) as decline_ct\n",
    ",count(distinct(a.order_token_loss)) as approved_order_Ct\n",
    ",sum(in_flight_order_amount) as attempt_Amt\n",
    ",sum(order_amount_local) as approved_amt\n",
    ",max(c.token_ct) as attempt_ct\n",
    ",count(distinct a.order_token)/max(c.token_ct) as decline_rt\n",
    ",div0(sum(case when is_in_attempt_control_Group = 1 then p2_overdue_d0_local end),sum(case when is_in_attempt_control_Group = 1 then p2_due_local end)) as ctrl_Group_p2d0\n",
    ",div0(sum(p2_overdue_d0_local),sum( p2_due_local)) as portfolio_p2_do\n",
    "\n",
    ",sum(case when b.order_Token is not null then in_flight_order_amount end) as decline_amt\n",
    "from jobys_latest_attempts a\n",
    "left join (select distinct order_token, rule_id from full_declines where rule_Category not in ('SF', 'ATO', 'UNAUTH') ) b\n",
    "on a.order_token = b.order_token\n",
    "left join decline_rt_denom c\n",
    "on a.par_region = c.par_Region\n",
    "and a.bp_is_sup = c.bp_is_sup\n",
    "and a.par_process_date = c.par_process_date\n",
    "where a.par_process_date >=  DATEADD('day', -33, CURRENT_DATE())\n",
    "\n",
    "group by 1,2,3,4\n",
    "order by 1,2,3,4 desc;''')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "260ea8eb-40fc-47d0-b959-3560580dfca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_rule_change_report(df, focus_region='US', top_n=10, bp_is_sup = None, ref_date=None, min_decline_rt = .01, conn=conn):\n",
    "    df['par_process_date'] = pd.to_datetime(df['par_process_date'])\n",
    "    ref_date = pd.to_datetime(ref_date) if ref_date else df['par_process_date'].max()\n",
    "\n",
    "    # Filter for current region and baseline day\n",
    "    df = df[(df['par_region'] == f'{focus_region}') & (df['bp_is_sup'] == bp_is_sup)]\n",
    "\n",
    "    # Define historical reference dates\n",
    "     # Reference date mapping\n",
    "    dates = {\n",
    "        'today': ref_date,\n",
    "        'yesterday': ref_date - pd.Timedelta(days=1),\n",
    "        'last_week': ref_date - pd.Timedelta(days=7),\n",
    "        'last_month': ref_date - pd.Timedelta(days=30)\n",
    "    }\n",
    "\n",
    "    # Keep only those dates\n",
    "    df_compare = df[df['par_process_date'].isin(dates.values())]\n",
    "    metrics = ['decline_ct', 'attempt_ct', 'decline_rt']\n",
    "\n",
    "    rule_summary = (\n",
    "        df_compare\n",
    "        .groupby(['rule_id', 'par_process_date'])[metrics]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    pivot = rule_summary.pivot(index='rule_id', columns='par_process_date', values=metrics)\n",
    "    pivot.columns = [f\"{m}_{d.strftime('%Y-%m-%d')}\" for m, d in pivot.columns]\n",
    "    pivot = pivot.reset_index()\n",
    "\n",
    "    # Helper functions\n",
    "    def pct_change(new, old):\n",
    "        if pd.isna(new) or pd.isna(old) or old == 0:\n",
    "            return None\n",
    "        return (new - old) / old * 100\n",
    "\n",
    "    def fmt(val, pct=False):\n",
    "        if pd.isna(val):\n",
    "            return \"N/A\"\n",
    "        return f\"{val:.2%}\" if pct else f\"{val:,.0f}\"\n",
    "\n",
    "    def fmt_pct(val): return f\"{val:+.1f}%\" if val is not None else \"N/A\"\n",
    "\n",
    "    # Date suffixes\n",
    "    t = dates['today'].strftime('%Y-%m-%d')\n",
    "    y = dates['yesterday'].strftime('%Y-%m-%d')\n",
    "    w = dates['last_week'].strftime('%Y-%m-%d')\n",
    "    m = dates['last_month'].strftime('%Y-%m-%d')\n",
    "\n",
    "    # Calculate deltas\n",
    "    pivot['delta_decline_rt_y'] = pivot.apply(lambda r: pct_change(r.get(f'decline_rt_{t}'), r.get(f'decline_rt_{y}')), axis=1)\n",
    "    pivot['delta_decline_rt_w'] = pivot.apply(lambda r: pct_change(r.get(f'decline_rt_{t}'), r.get(f'decline_rt_{w}')), axis=1)\n",
    "    pivot['delta_decline_rt_m'] = pivot.apply(lambda r: pct_change(r.get(f'decline_rt_{t}'), r.get(f'decline_rt_{m}')), axis=1)\n",
    "    pivot['delta_decline_ct'] = pivot.get(f'decline_ct_{t}', 0) - pivot.get(f'decline_ct_{y}', 0)\n",
    "\n",
    "    # Absolute values for sorting\n",
    "    pivot['abs_rt_change_y'] = pivot['delta_decline_rt_y'].abs()\n",
    "    pivot['abs_rt_change_w'] = pivot['delta_decline_rt_w'].abs()\n",
    "    pivot['abs_rt_change_m'] = pivot['delta_decline_rt_m'].abs()\n",
    "\n",
    "    # Apply threshold filter\n",
    "    pivot = pivot[pivot[f'decline_rt_{t}'] > min_decline_rt]\n",
    "\n",
    "    # Top N rules by absolute daily decline rate change\n",
    "    top_rules = pivot.sort_values(by=['abs_rt_change_y', 'abs_rt_change_w', 'abs_rt_change_m'], ascending=False).head(top_n)\n",
    "\n",
    "    # Assemble report\n",
    "    lines = [f\"ðŸ“Š *Top {top_n} Rule Decline Rate Movers for {focus_region} on {t} (Filtered: decline rate > {min_decline_rt:.0%})*\"]\n",
    "\n",
    "    for _, row in top_rules.iterrows():\n",
    "        rid = row['rule_id']\n",
    "        attempts = row.get(f'attempt_ct_{t}', 0)\n",
    "        declines = row.get(f'decline_ct_{t}', 0)\n",
    "        drt = row.get(f'decline_rt_{t}', None)\n",
    "\n",
    "        lines.append(\n",
    "            f\"\\nðŸ”¹ Rule `{rid}`: {int(attempts)} attempts, {int(declines)} declines\"\n",
    "            f\"\\n  - Decline Rate: {fmt(drt, pct=True)}\"\n",
    "            f\"\\n  - vs Yesterday: {fmt_pct(row['delta_decline_rt_y'])}\"\n",
    "            f\"\\n  - vs Last Week: {fmt_pct(row['delta_decline_rt_w'])}\"\n",
    "            f\"\\n  - vs Last Month: {fmt_pct(row['delta_decline_rt_m'])}\"\n",
    "        )   \n",
    "    output= \"\\n\".join(lines)\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83375e51-d863-4bfe-9188-a258d9092db8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "rule_daily_dive.loc[(rule_daily_dive.rule_id == 'US_fraud_online_new_user_risky_card_issuing_bank') & (rule_daily_dive.bp_is_sup==1)].sort_values(by='par_process_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4197383-0a68-4ebe-940a-4e9183d2a3c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate_rule_change_report(rule_daily_dive, focus_region='US', top_n=10, bp_is_sup = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81fd8565-eab4-4697-9a77-e9e37ee99414",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generate_rule_change_report(rule_daily_dive, focus_region='US', top_n=10, bp_is_sup = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23d68f08-f50f-4837-81ba-970ee128eb31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[(df['bp_is_sup'] == 0) & (df['par_region']=='US')].sort_values(by='par_process_date')[['par_region','par_process_date','attempt_ct','approved_amt','decline_rt','portfolio_p2_do']].tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b703b3e9-28cc-43da-9b9e-b1dc45077778",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[(df['bp_is_sup'] == 0) & (df['par_region']=='AU')].sort_values(by='par_process_date')[['par_region','par_process_date','attempt_ct','approved_amt','decline_rt','portfolio_p2_do']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40f1622-f4e1-423a-bd1d-249d5f1a2b95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[(df['bp_is_sup'] == 1) & (df['par_region']=='US')].sort_values(by='par_process_date')[['par_region','par_process_date','attempt_ct','approved_amt','decline_rt','portfolio_p2_do']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "416b3a52-ff39-41eb-bc7e-7517f2fd9733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[(df['bp_is_sup'] == 1) & (df['par_region']=='US')].sort_values(by='par_process_date')[['par_region','par_process_date','attempt_ct','approved_amt','decline_rt','portfolio_p2_do']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37df73d4-2792-41a7-a5df-9585625d60f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ade2986-917b-4637-9961-116241334e72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# --- Step 3: Plot for bp_is_sup = 1 ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=df_sup_0_agg,\n",
    "    x='par_process_date',\n",
    "    y='decline_rt',\n",
    "    hue='par_region',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('Decline Rate Over Time by Region (bp_is_sup = 0)')\n",
    "plt.xlabel('Processing Date')\n",
    "plt.ylabel('Decline Rate')\n",
    "plt.legend(title='Region')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33fb9f00-f808-4459-a4e2-1f6d8b29113c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Filter by bp_is_sup values ---\n",
    "df_sup_1 = df[df['bp_is_sup'] == 1]\n",
    "df_sup_0 = df[df['bp_is_sup'] == 0]\n",
    "\n",
    "# --- Step 2: Group and aggregate the data by date and region ---\n",
    "df_sup_1_agg = df_sup_1.groupby(['par_process_date', 'par_region'])['portfolio_p2_do'].mean().reset_index()\n",
    "df_sup_0_agg = df_sup_0.groupby(['par_process_date', 'par_region'])['portfolio_p2_do'].mean().reset_index()\n",
    "\n",
    "# --- Step 3: Plot for bp_is_sup = 1 ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=df_sup_1_agg,\n",
    "    x='par_process_date',\n",
    "    y='portfolio_p2_do',\n",
    "    hue='par_region',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('Decline Rate Over Time by Region (bp_is_sup = 1)')\n",
    "plt.xlabel('Processing Date')\n",
    "plt.ylabel('portfolio_p2_do Rate')\n",
    "plt.legend(title='Region')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3589830-1315-4363-953f-4456325dd303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sup_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68c93ab4-88ee-45a2-bff4-6e7960622dc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 2: Group and aggregate the data by date and region ---\n",
    "df_sup_1_agg = df_sup_1.groupby(['par_process_date', 'par_region'])['portfolio_p2_do'].mean().reset_index()\n",
    "df_sup_0_agg = df_sup_0.groupby(['par_process_date', 'par_region'])['portfolio_p2_do'].mean().reset_index()\n",
    "\n",
    "# --- Step 3: Plot for bp_is_sup = 1 ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=df_sup_1_agg,\n",
    "    x='par_process_date',\n",
    "    y='portfolio_p2_do',\n",
    "    hue='par_region',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('Decline Rate Over Time by Region (bp_is_sup = 1)')\n",
    "plt.xlabel('Processing Date')\n",
    "plt.ylabel('portfolio_p2_do Rate')\n",
    "plt.legend(title='Region')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b96302a-ea97-49c2-bda3-6d5ed8d8f550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=df_sup_0_agg,\n",
    "    x='par_process_date',\n",
    "    y='portfolio_p2_do',\n",
    "    hue='par_region',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('P2D0_RATE by Region (bp_is_sup = 0)')\n",
    "plt.xlabel('Processing Date')\n",
    "plt.ylabel('portfolio_p2_do Rate')\n",
    "plt.legend(title='Region')\n",
    "plt.ylim(0, .5)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e09a5f9b-200f-4616-ad17-e58600016d1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=df_sup_1_agg,\n",
    "    x='par_process_date',\n",
    "    y='portfolio_p2_do',\n",
    "    hue='par_region',\n",
    "    marker='o'\n",
    ")\n",
    "plt.title('P2D0_RATE by Region (bp_is_sup = 1)')\n",
    "plt.xlabel('Processing Date')\n",
    "plt.ylabel('portfolio_p2_do Rate')\n",
    "plt.legend(title='Region')\n",
    "plt.ylim(0, .5)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e11f244b-b926-4455-9f0a-f2cff079371f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "7_20 Daily Portfolio Monitoring",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
